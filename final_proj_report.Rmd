---
title: "BST210 Final Project Report Appendix"
author: "Ziqian Liao, Joanna Shen"
date: "2022-12-06"
output: pdf_document
---

# Data wrangling

```{r}
long_df <- read.csv("oasis_longitudinal.csv")
```

```{r}
# packages
library(dplyr)
library(ggplot2)
library(splines)
library(splines2)
library(haven)
library(survival)
```

```{r}
table(long_df$Group, long_df$CDR)
```

```{r}
#correct a few cases that might have incorrect data input of CDR 
#(categorized as nondemented while cdr is not 0)
long_df %>% filter(Group == 'Nondemented') %>% filter(CDR == 0.5)
long_df_c <- long_df
long_df_c[long_df_c$Group == 'Nondemented'& long_df_c$CDR == 0.5,]$CDR <- 0.0
table(long_df_c$Group, long_df_c$CDR)
```

```{r}
#create a binary outcome version of the longitudinal data by collapsing 
#each individual's information into one observation (drop all but last visit)
long_df_c_original <- long_df_c
long_df_c[long_df_c$Group == 'Converted' & long_df_c_original$CDR == 0,]$Group <- 'Nondemented'
long_df_c[long_df_c$Group == 'Converted' & long_df_c_original$CDR != 0,]$Group <- 'Demented'
long_df_binary <- long_df_c %>% group_by(Subject.ID) %>% slice(n())
```

```{r}
#to facilitate interpretation
long_df_binary$EDUCcat <- case_when(
  long_df_binary$EDUC <= 12 ~ 1, #less than or equal to high school level
  long_df_binary$EDUC > 12 & long_df_binary$EDUC <= 16 ~ 2, #college level
  TRUE ~ 3, #above college
)
```

```{r}
# we will only include one of the two (eTIV) given the very strong linear correlation
plot(long_df_binary$eTIV ~ long_df_binary$ASF)
cor(long_df_binary$eTIV,long_df_binary$ASF)

# we will only include one of the two (EDUC) given the strong linera correlation
cor(long_df_binary$EDUCcat,long_df_binary$SES, use = "complete.obs")
```

```{r}
#table of NA values
colSums(is.na(long_df_binary))
#percent of NA values
round(colSums(is.na(long_df_binary))/nrow(long_df_binary),4)
#dealing with NA - SES
#SES has NAs > 5% but is strongly correlated with EDUCcat
long_df_binary <- long_df_binary %>% select(-SES)
#dealing with NA - MMSE
#MMSE has NA < 5% 
#only 1 NA, should be reasonable to fill the data with the individual's previous record
tempid <- long_df_binary %>% filter(is.na(MMSE)) %>% pull(Subject.ID)
long_df_c %>% filter(Subject.ID %in% tempid) %>% select(Subject.ID, Group, Visit, MMSE)
long_df_binary[is.na(long_df_binary$MMSE),]$MMSE <- 26
#NA table after cleaning
colSums(is.na(long_df_binary))
```

```{r}
#correct data types before model fitting 
long_df_binary$Group <- factor(long_df_binary$Group)
#use 'nondemented' as the reference group
long_df_binary$Group <- relevel(long_df_binary$Group, ref = 'Nondemented')
long_df_binary$M.F <- factor(long_df_binary$M.F)
```

# Exploratory Data Analysis (EDA)

## Data visualization with each potential predictor individually)

```{r}
# categorical vs. categorical
with(long_df_binary, table(M.F, Group))
with(long_df_binary, table(EDUCcat, Group))

# continuous vs. categorical
ggplot(long_df_binary, aes(Age, Group)) +
  geom_boxplot()
ggplot(long_df_binary, aes(eTIV, Group)) +
  geom_boxplot()
ggplot(long_df_binary, aes(nWBV, Group)) +
  geom_boxplot()
```

# Modeling

## Linear (with model selection)

```{r}
#linear model
lm_linear <- lm(nWBV~Age, data = long_df_binary)
summary(lm_linear)
#test model assumption
plot(lm_linear)
hist(lm_linear$residuals)
#checking influential points
cooksd<-cooks.distance(lm_linear)
summary(cooksd)
n<-length(cooksd)
long_df_binary$cooksd <- cooksd
long_df_binary[cooksd>4/(n-2),]
```

```{r}
#quadratic model
lm_quad <- lm(nWBV~Age + I(Age^2), data = long_df_binary)
plot(lm_quad)
hist(lm_quad$residuals)

#cubic model
lm_cub <- lm(nWBV~Age + I(Age^2) + I(Age^3), data = long_df_binary)

#model comparison with ANOVA
anova(lm_linear, lm_quad)
anova(lm_quad, lm_cub)

#model comparison with AIC and adjusted R^2
df_compare <- data.frame(cbind(c('linear','quadratic','cubic'),c(AIC(lm_linear),AIC(lm_quad),AIC(lm_cub)),c(summary(lm_linear)$adj.r.squared,summary(lm_quad)$adj.r.squared,summary(lm_cub)$adj.r.squared)))
colnames(df_compare) <- c('model','AIC','adjusted R^2')
df_compare

#quadratic is the most favored model
summary(lm_quad)
```
## Logistic (with model selection)

### Using a single predictor

```{r}
# estimated total intracranial volume
logit_etiv <- glm(Group ~ eTIV, family=binomial(), data=long_df_binary)
summary(logit_etiv)

# normalized whole-brain volume
logit_nwbv <- glm(Group ~ nWBV, family=binomial(), data=long_df_binary)
summary(logit_nwbv)
```

### Using both of the potential predictors

```{r}
logit_both <- glm(Group ~ eTIV + nWBV, family=binomial(), data=long_df_binary)
anova(logit_nwbv, logit_both, test="Chisq")
```

The ANOVA allows us to test the hypothesis $H_0$: the model using normalized whole-brain volume (the reduced model) is sufficient versus $H_1$: the model using both estimated total intracranial volume and normalized whole-brain volume (the full model) is preferred. The ANOVA table shows a p-value of 0.3226. Based on a significance level $\alpha = 0.05$, we fail to reject the null hypothesis. Thus, the reduced model is sufficient. Therefore, we think using normalized whole-brain volume alone better models the effect on dementia.

### Comparing continuous vs. ordinal vs. categorical

```{r}
long_df_binary <- long_df_binary %>% mutate(nWBVcat = case_when(
  nWBV < 0.675 ~ 1,
  nWBV >= 0.675 & nWBV < 0.7 ~ 2,
  nWBV >= 0.7 & nWBV < 0.725 ~ 3,
  nWBV >= 0.725 & nWBV < 0.75 ~ 4,
  nWBV >= 0.75 & nWBV < 0.775 ~ 5,
  TRUE ~ 6
))
```

```{r}
# ordinal
logit_nwbv_ord <- glm(Group ~ nWBVcat, family=binomial(), data=long_df_binary)
summary(logit_nwbv_ord)

# categorical
logit_nwbv_cat <- glm(Group ~ as.factor(nWBVcat), family=binomial(), data=long_df_binary)
summary(logit_nwbv_cat)
```

```{r}
plot(logit_nwbv$fitted.values~long_df_binary$nWBV,type='p',col='black',ylab="P(dementia)",xlab="Normalized whole-brain volume")
lines(logit_nwbv_ord$fitted.values~long_df_binary$nWBV,type='p',col="red")
legend('bottomright',legend=c("linear","ordinal"),pch=c(1,1),col=c(1,2))
```

```{r}
anova(logit_nwbv_ord, logit_nwbv_cat, test="Chisq")
```

### Comparing linear vs. quadratic vs. cubic

```{r}
# quadratic
logit_nwbv_quad <- glm(Group ~ nWBV + I(nWBV^2), family = binomial(), data = long_df_binary)
summary(logit_nwbv_quad)

# cubic
logit_nwbv_cub <- glm(Group ~ nWBV + I(nWBV^2) + I(nWBV^3), family = binomial(), data = long_df_binary)
summary(logit_nwbv_cub)
```

Better fitting models have smaller AIC values. The AIC value of the model using linear normalized whole-brain volume is smaller than the AIC value of the model using quadratic normalized whole-brain volume, which is smaller than the AIC value of the model using cubic normalized whole-brain volume. We can reach the same conclusion that the model using linear normalized whole-brain volume is better by comparing the p-values, based on a significance level $\alpha = 0.05$.

### Potential confounders

#### Is sex a confounder?

Sex is a risk factor for dementia and sex is associated with normalized whole-brain volume, but not a consequence of normalized whole-brain volume. The classic definition of confounding is that a variable C is a confounding factor of the association between X and Y, if C satisfies two conditions: (1) C is a risk factor of the outcome Y and (2) C is associated with exposure X, but not a consequence of exposure X. Thus, sex meets the classic definition of a confounder, and so we need to check whether sex meets the statistical (operational) definition of a confounder via the 10% rule.

```{r}
boxplot(nWBV~M.F,data=long_df_binary)
```

```{r}
logit_nwbv_sex <- glm(Group~ nWBV + M.F, family=binomial(), data=long_df_binary)
summary(logit_nwbv_sex)
100*((coef(logit_nwbv)[2]-coef(logit_nwbv_sex)[2])/coef(logit_nwbv_sex)[2])
```

Including the potential confounder sex in the model with normalized whole-brain volume changes the parameter estimate for normalized whole-brain volume by more than 10%, so sex is a confounder of the effect of normalized whole-brain volume on dementia.

#### Is square age a confounder?

Square age is a risk factor for dementia and square age is associated with normalized whole-brain volume, but not a consequence of normalized whole-brain volume. Thus, square age meets the classic definition of a confounder, and so we need to check whether square age meets the statistical (operational) definition of a confounder via the 10% rule.

```{r}
logit_nwbv_age <- glm(Group~ nWBV + I(Age^2), family=binomial(), data=long_df_binary)
summary(logit_nwbv_age)
100*((coef(logit_nwbv)[2]-coef(logit_nwbv_age)[2])/coef(logit_nwbv_age)[2])
```

Including the potential confounder square age in the model with normalized whole-brain volume changes the parameter estimate for normalized whole-brain volume by more than 10%, so square age is a confounder of the effect of normalized whole-brain volume on dementia.

### Is education level a confounder?

```{r}
boxplot(nWBV~EDUCcat,data=long_df_binary)
```

```{r}
logit_nwbv_ed <- glm(Group~ nWBV + EDUCcat, family=binomial(), data=long_df_binary)
summary(logit_nwbv_ed)
100*((coef(logit_nwbv)[2]-coef(logit_nwbv_ed)[2])/coef(logit_nwbv_ed)[2])
```

Including the potential confounder education level in the model with normalized whole-brain volume changes the parameter estimate for normalized whole-brain volume by less than 10%, so education level is not a confounder of the effect of normalized whole-brain volume on dementia.

```{r}
logit_nwbv_sex_age <- glm(Group~ nWBV + M.F + I(Age^2), family=binomial(), data=long_df_binary)
anova(logit_nwbv, logit_nwbv_sex_age, test="Chisq")
```

### Potential effect modifiers

The p-values of the interaction terms are 0.55592 (for sex), 0.794 (for age), and 0.3542 (for education level), respectively. Based on a significance level $\alpha = 0.05$, we reject the null hypothesis in each case. Thus, none of sex, age, and education level is an effect modifier of the effect of normalized whole-brain volume on dementia.

#### Is sex an effect modifier?

```{r}
logit_nwbv_nwbv.sex <- glm(Group~nWBV+M.F+nWBV*M.F, family=binomial(), data=long_df_binary)
summary(logit_nwbv_nwbv.sex)
```

#### Is age an effect modifier?

```{r}
logit_nwbv_nwbv.age <- glm(Group~nWBV+I(Age^2)+nWBV*I(Age^2), family=binomial(), data=long_df_binary)
summary(logit_nwbv_nwbv.age)
```

#### Is education level an effect modifier?

```{r}
logit_nwbv_nwbv.ed <- glm(Group~nWBV+EDUCcat+nWBV*EDUCcat, family=binomial(), data=long_df_binary)
summary(logit_nwbv_nwbv.ed)
```

#### Comparing linear vs. quadratic

```{r}
summary(logit_nwbv_sex_age)
```

```{r}
logit_nwbv_quad_sex_age <- glm(Group~ nWBV + M.F + I(Age^2) + I(nWBV^2), family=binomial(), data=long_df_binary)
summary(logit_nwbv_quad_sex_age)
```

```{r}
anova(logit_nwbv_sex_age, logit_nwbv_quad_sex_age, test="Chisq")
```

#### Interpretation

```{r}
plot(logit_nwbv_sex_age$fitted.values~long_df_binary$nWBV,
     type='p',col='cyan4',
     ylab="P(dementia)",xlab="Normalized whole-brain volume")
```

```{r}
exp(coef(logit_nwbv_sex_age)[1])
exp(coef(logit_nwbv_sex_age)[2])
exp(coef(logit_nwbv_sex_age)[3])
exp(coef(logit_nwbv_sex_age)[4])
```

### Survival Analysis

#### Data wrangling

```{r}
long_df[long_df$Group == 'Nondemented' & long_df$CDR != 0,]$CDR <- 0

filtered <- long_df %>% group_by(Subject.ID) %>% summarise(nvisit = n()) %>% filter(nvisit > 1) 

list <- filtered$Subject.ID

surv_info <- long_df %>% group_by(Subject.ID) %>% mutate(cdr_diff_max = max(CDR) - min(CDR)) %>% mutate(cdr_diff_lag =  CDR - lag(CDR)) %>% filter(Subject.ID %in% list) %>% select(Subject.ID, Visit, CDR, cdr_diff_max, cdr_diff_lag, Age) %>% mutate(cdr_change = as.numeric(cdr_diff_lag > 0)) 

surv_df <- surv_info %>% summarize(result = max(cdr_change, na.rm = TRUE), years = ifelse(result == 0, max(Age) - min(Age), NA))

surv_df$years[surv_df$Subject.ID == 'OAS2_0007'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0014'] <- 1
surv_df$years[surv_df$Subject.ID == 'OAS2_0018'] <- 5
surv_df$years[surv_df$Subject.ID == 'OAS2_0020'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0028'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0031'] <- 5
surv_df$years[surv_df$Subject.ID == 'OAS2_0041'] <- 4
surv_df$years[surv_df$Subject.ID == 'OAS2_0046'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0050'] <- 1
surv_df$years[surv_df$Subject.ID == 'OAS2_0054'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0079'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0087'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0089'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0092'] <- 1
surv_df$years[surv_df$Subject.ID == 'OAS2_0103'] <- 5
surv_df$years[surv_df$Subject.ID == 'OAS2_0104'] <- 1
surv_df$years[surv_df$Subject.ID == 'OAS2_0114'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0118'] <- 4
surv_df$years[surv_df$Subject.ID == 'OAS2_0120'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0127'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0133'] <- 3
surv_df$years[surv_df$Subject.ID == 'OAS2_0144'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0145'] <- 5
surv_df$years[surv_df$Subject.ID == 'OAS2_0150'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0160'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0164'] <- 2
surv_df$years[surv_df$Subject.ID == 'OAS2_0176'] <- 5
surv_df$years[surv_df$Subject.ID == 'OAS2_0181'] <- 1
surv_df$years[surv_df$Subject.ID == 'OAS2_0184'] <- 1

temp <- long_df_binary %>% select(Subject.ID, nWBV)
surv_df <- surv_df %>% left_join(temp, by = c('Subject.ID'))

surv_df
```

```{r}
summary(surv_df)
```

```{r}
surv_df <- surv_df %>% mutate(nWBV_new = case_when(
  nWBV < 0.7125 ~ 1,
  TRUE ~ 2)
)

surv_df$nWBV_new = factor(surv_df$nWBV_new)
```

#### Kaplan-Meier survival estimate

```{r}
y <- Surv(surv_df$years, surv_df$result)

# log-log CI
ys_loglog <- survfit(y ~ 1, type="kaplan-meier", conf.type="log-log")
summary(ys_loglog)

# linear CI
ys_linear <- survfit(y ~ 1, type="kaplan-meier", conf.type="plain")
summary(ys_linear)
```

```{r}
# Kaplan-Meier survival curve
plot(ys_loglog, xlab="Years", ylab="Survival probability")
```

#### Cox

##### Normalized whole-brain volume

```{r}
surv_nwbv <- coxph(y ~ nWBV_new, ties = "efron", data = surv_df)
summary(surv_nwbv)
```

```{r}
# log(-log(S)) vs. log(t)
km_nwbv <- survfit(y ~ nWBV_new, data = surv_df)
plot(km_nwbv, fun = "cloglog", xlab = "Log(Time in years)",
     ylab = "Log-log survival", main = "Log-log curve by normalized whole-brain volume")
```


```{r}
# weighted Schoenfeld residual
resid.wt.scho <- cox.zph(surv_nwbv)
resid.wt.scho
plot(resid.wt.scho)
```