---
title: "BST210 Project 2nd Check-in Appendix"
author: "Ziqian Liao, Joanna Shen"
date: "2022-11-03"
output: pdf_document
---

# Data Wrangling

```{r}
long_df <- read.csv("oasis_longitudinal.csv")
```

```{r}
library(dplyr)
library(ggplot2)
library(splines)
library(splines2)
library(haven)
```

```{r}
table(long_df$Group, long_df$CDR)
```

```{r}
#correct a few cases that might have incorrect data input of CDR 
#(categorized as nondemented while cdr is not 0)
long_df %>% filter(Group == 'Nondemented') %>% filter(CDR == 0.5)
long_df_c <- long_df
long_df_c[long_df_c$Group == 'Nondemented'& long_df_c$CDR == 0.5,]$CDR <- 0.0
table(long_df_c$Group, long_df_c$CDR)
```

```{r}
#data wrangling
#create a binary outcome version of the longitudinal data by collapsing 
#each individual's information into one observation (drop all but last visit)

long_df_c_original <- long_df_c

long_df_c[long_df_c$Group == 'Converted' & long_df_c_original$CDR == 0,]$Group <- 'Nondemented'

long_df_c[long_df_c$Group == 'Converted' & long_df_c_original$CDR != 0,]$Group <- 'Demented'

long_df_binary <- long_df_c %>% group_by(Subject.ID) %>% slice(n())

```

```{r}
#table of NA values
colSums(is.na(long_df_binary))
#percent of NA values
round(colSums(is.na(long_df_binary))/nrow(long_df_binary),4)

#dealing with NA - SES
#SES has NAs > 5% 
long_df_binary <- long_df_binary %>% select(-SES)

#dealing with NA - MMSE
#MMSE has NA < 5% 
#only 1 NA, should be reasonable to fill the data with the individual's previous record
tempid <- long_df_binary %>% filter(is.na(MMSE)) %>% pull(Subject.ID)
long_df_c %>% filter(Subject.ID %in% tempid) %>% select(Subject.ID, Group, Visit, MMSE)
long_df_binary[is.na(long_df_binary$MMSE),]$MMSE <- 26

#NA table after cleaning
colSums(is.na(long_df_binary))
```

```{r}
#correct data types before model fitting 
long_df_binary$Group <- as.factor(long_df_binary$Group)
#use 'nondemented' as the reference group
long_df_binary$Group <- relevel(long_df_binary$Group, ref = 'Nondemented')
long_df_binary$M.F <- as.factor(long_df_binary$M.F)
```

# Modeling

## Linear

EDA

```{r}
ggplot(long_df_binary, aes(Age, nWBV))+
  geom_point()

#linear model
lm_linear <- lm(nWBV~Age, data = long_df_binary)
summary(lm_linear)

#test model assumption
plot(lm_linear)
hist(lm_linear$residuals)

#checking influential points
cooksd<-cooks.distance(lm_linear)
summary(cooksd)
n<-length(cooksd)
long_df_binary$cooksd <- cooksd
long_df_binary[cooksd>4/(n-2),]
```

Model Selection 

```{r}
#quadratic model
lm_quad <- lm(nWBV~Age + I(Age^2), data = long_df_binary)
plot(lm_quad)
hist(lm_quad$residuals)

#cubic model
lm_cub <- lm(nWBV~Age + I(Age^2) + I(Age^3), data = long_df_binary)

#spline model with degree of freedom of 3
lm_spline <- lm(nWBV~bSpline(Age, df = 3),
                data=long_df_binary)

#Model comparison with ANOVA
anova(lm_linear, lm_quad)
anova(lm_quad, lm_cub)

#model comparison with AIC and adjusted R^2
df_compare <- data.frame(cbind(c('linear','quadratic','cubic','spline'),c(AIC(lm_linear),AIC(lm_quad),AIC(lm_cub),AIC(lm_spline)),c(summary(lm_linear)$adj.r.squared,summary(lm_quad)$adj.r.squared,summary(lm_cub)$adj.r.squared,summary(lm_spline)$adj.r.squared)))
colnames(df_compare) <- c('model','AIC','adjusted R^2')

df_compare

#quadratic is the most favored model
summary(lm_quad)
```


## Logistic

EDA & Data wrangling

```{r}
#EDA
table(long_df_binary$Group)

ggplot(long_df_binary, aes(Group, nWBV))+
  geom_boxplot()

#Data wrangling to facilitate interpretation 
long_df_binary$nWBVperc <- long_df_binary$nWBV*100

#logistic regression Group ~ nWBV
logit <- glm(Group~nWBVperc,family=binomial(),data=long_df_binary)
summary(logit)
```

Model Selection 

```{r}
#covariate: compare linear vs. quadratic vs. cubic
long_df_binary$nWBV2 <- (long_df_binary$nWBVperc)^2
logit_quad <- glm(Group~nWBV+nWBV2,family=binomial(),data=long_df_binary)

long_df_binary$nWBV3 <- (long_df_binary$nWBVperc)^3
logit_cub <- glm(Group~nWBV+nWBV2+nWBV3,family=binomial(),data=long_df_binary)

plot(logit$fitted.values~long_df_binary$nWBVperc,type='p',col='black',ylab="P(dementia)",xlab="nWBV")
lines(logit_quad$fitted.values~long_df_binary$nWBVperc,type='p',col="red")
lines(logit_cub$fitted.values~long_df_binary$nWBVperc,type='p',col="blue")
legend('bottomright',legend=c("linear","quadratic","cubic"),pch=c(1,1),col=c(1,2))
#not much difference, move on with linear

```

```{r}
#based on the linear model nWBV vs. Age, we may consider Age as a potential confounder 
#is Age a confounder? 
# + classical definition of confounder
logit_cat2_conf <- glm(Group~ nWBVperc + Age,
                       family=binomial(),
                       data=long_df_binary)
summary(logit) #raw
summary(logit_cat2_conf) #adjusted

#is Age an effect modifier? No
logit_cat2_em <- glm(Group~nWBVperc + nWBVperc*Age,
                family=binomial(),
                data=long_df_binary)
summary(logit_cat2_em)

#we will move on with Group~nWBVcat + Age

#confirm that the more complex model is favored via chi-square test
anova(logit,logit_cat2_conf, test="Chisq")

logit_final <- logit_cat2_conf

#fitted by final model of choice
plot(logit_final$fitted.values~long_df_binary$nWBVperc,type='p',col='cyan4',ylab="P(dementia)",xlab="nWBVperc")

#interpretation
exp(-0.25452)
#makes more sense to use reciprocal
1/exp(-0.25452)
```


## Poisson

Data wrangling

```{r}
long_df_binary$nWBVcat <- case_when(
  long_df_binary$nWBV < 0.7 ~ 1,
  long_df_binary$nWBV >= 0.7 & long_df_binary$nWBV < 0.725 ~ 2,
  long_df_binary$nWBV >= 0.725 & long_df_binary$nWBV < 0.75 ~ 3,
  long_df_binary$nWBV >= 0.75 & long_df_binary$nWBV < 0.775 ~ 4,
  long_df_binary$nWBV >= 0.775 ~ 5
)

long_df_binary$EDUCcat <- case_when(
  long_df_binary$EDUC <= 12 ~ 1, #less than or equal to high school level
  long_df_binary$EDUC > 12 & long_df_binary$EDUC <= 16 ~ 2, #college level
  long_df_binary$EDUC > 16 ~ 3, #above college
) 

long_FU <- long_df_c %>% filter(Group == 'Nondemented') %>% group_by(Subject.ID) %>% summarize(FU_duration = max(Age) - min(Age))

long_df_binary <- left_join(long_df_binary, long_FU, by = "Subject.ID")
long_df_binary[is.na(long_df_binary$FU_duration),]$FU_duration <- 0

long_df_poisson <- long_df_binary %>% 
  select(Group, nWBVcat, EDUCcat, FU_duration) %>% 
  group_by(nWBVcat, EDUCcat) %>% 
  summarize(Cases = sum(Group == 'Demented'),
            personyear = sum(FU_duration))
```

EDA

```{r}
#basic plot to inspect the suitability of using poisson family
library(vcd)
fit<-goodfit(long_df_poisson$Cases)
rootogram(fit)

distplot(long_df_poisson$Cases, type="poisson")
distplot(long_df_poisson$Cases, type="nbinom")
#poisson and/or negative binomial would be a good fit
```

```{r}
# Initial poisson model fitting
poi_nWBV <- glm(Cases ~ nWBVcat, offset=log(personyear), data=long_df_poisson, family=poisson())

#check dispersion
library(AER)
dispersiontest(poi_nWBV)
poi_nWBV$deviance/poi_nWBV$df.residual
#the over-dispersion issue should be addressed

#check zero inflation
table(long_df_poisson$Cases)
#no zero inflation issue
```
```{r}
#address overdispersion by using negative binomial model
poi_nb <- MASS::glm.nb(Cases ~ nWBVcat + offset(log(personyear)), data=long_df_poisson)
summary(poi_nb)
```

Model Selection

```{r}
#Examining confounding
poi_conf <-  MASS::glm.nb(Cases ~ nWBVcat + EDUCcat + offset(log(personyear)), data=long_df_poisson)
summary(poi_conf)

#Examining effect modification 
poi_em <- MASS::glm.nb(Cases ~ nWBVcat + EDUCcat*nWBVcat + offset(log(personyear)), data=long_df_poisson)
summary(poi_em)
#EDUCat is not an effect modifier
```

```{r}
#interpret beta_1
exp(coef(poi_nb)[2])
#would make more sense to use reciprocal in interpretation in this case
1/exp(coef(poi_nb)[2])
```



